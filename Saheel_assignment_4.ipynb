{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9994f4f-81ec-4bdf-924f-b0a45dc2fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bf5865-0cfc-4caa-9f56-1d93460a5608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahee\\AppData\\Local\\Temp\\ipykernel_21876\\1529368496.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n",
    "import time\n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bf27c8-bb74-4e7d-816f-981c536ee992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[19]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[24]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[26]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[27]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[28]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[34]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[36]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[37]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[38]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"[41]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[47]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[50]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[51]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[19]   \n",
       "6    7.                \"Phonics Song with Two Words\"[24]   \n",
       "7    8.                          \"Wheels on the Bus\"[25]   \n",
       "8    9.                                \"Uptown Funk\"[26]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[27]   \n",
       "10  11.                              \"Gangnam Style\"[28]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[33]   \n",
       "12  13.                             \"Dame Tu Cosita\"[34]   \n",
       "13  14.                                     \"Axel F\"[35]   \n",
       "14  15.                                      \"Sugar\"[36]   \n",
       "15  16.                                       \"Roar\"[37]   \n",
       "16  17.                             \"Counting Stars\"[38]   \n",
       "17  18.                                      \"Sorry\"[39]   \n",
       "18  19.                        \"Baa Baa Black Sheep\"[40]   \n",
       "19  20.                          \"Thinking Out Loud\"[41]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "21  22.                                 \"Dark Horse\"[43]   \n",
       "22  23.                             \"Lakdi Ki Kathi\"[44]   \n",
       "23  24.                                      \"Faded\"[45]   \n",
       "24  25.                                    \"Perfect\"[46]   \n",
       "25  26.                                 \"Let Her Go\"[47]   \n",
       "26  27.                             \"Girls Like You\"[48]   \n",
       "27  28.          \"Humpty the train on a fruits ride\"[49]   \n",
       "28  29.                                    \"Lean On\"[50]   \n",
       "29  30.                                   \"Bailando\"[51]   \n",
       "\n",
       "                                           Artist        Upload_date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.85  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.16  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.70  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.20  \n",
       "4                                      Ed Sheeran   January 30, 2017   6.00  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.89  \n",
       "6                                       ChuChu TV      March 6, 2014   5.30  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   5.24  \n",
       "8                                     Mark Ronson  November 19, 2014   4.92  \n",
       "9                                     Miroshka TV  February 27, 2018   4.89  \n",
       "10                                            Psy      July 15, 2012   4.80  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.35  \n",
       "13                                     Crazy Frog      June 16, 2009   3.91  \n",
       "14                                       Maroon 5   January 14, 2015   3.87  \n",
       "15                                     Katy Perry  September 5, 2013   3.80  \n",
       "16                                    OneRepublic       May 31, 2013   3.79  \n",
       "17                                  Justin Bieber   October 22, 2015   3.66  \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   3.64  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.60  \n",
       "20                                        Shakira       June 4, 2010   3.59  \n",
       "21                                     Katy Perry  February 20, 2014   3.52  \n",
       "22                                   Jingle Toons      June 14, 2018   3.48  \n",
       "23                                    Alan Walker   December 3, 2015   3.45  \n",
       "24                                     Ed Sheeran   November 9, 2017   3.45  \n",
       "25                                      Passenger      July 25, 2012   3.44  \n",
       "26                                       Maroon 5       May 31, 2018   3.42  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.41  \n",
       "28                                    Major Lazer     March 22, 2015   3.38  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.38  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating blank list\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Artist\n",
    "artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Views\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "for i in views:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Upload_date\n",
    "upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "for i in upload_date:\n",
    "    Upload_date.append(i.text)\n",
    "    \n",
    "Youtube_viewed=pd.DataFrame({})\n",
    "Youtube_viewed['Rank']=Rank\n",
    "Youtube_viewed['Name']=Name\n",
    "Youtube_viewed['Artist']=Artist\n",
    "Youtube_viewed['Upload_date']=Upload_date\n",
    "Youtube_viewed['Views']=Views\n",
    "Youtube_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6599c705-0559-4426-9692-5859ac95d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2)Scrape the details teamIndia’sinternationalfixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de09a2df-eef7-46ec-96fc-5e9702f12161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae56f556-c05f-4eb1-93ea-cf8d97568fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahee\\AppData\\Local\\Temp\\ipykernel_21876\\420871798.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n",
    "time.sleep(4)\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d29013-cfaa-4e59-a8c8-9fbfb33f15be",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: invalid locator\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00BE8893+48451]\n\t(No symbol) [0x00B7B8A1]\n\t(No symbol) [0x00A85058]\n\t(No symbol) [0x00AB0570]\n\t(No symbol) [0x00AB069B]\n\t(No symbol) [0x00ADDD92]\n\t(No symbol) [0x00ACA304]\n\t(No symbol) [0x00ADC482]\n\t(No symbol) [0x00ACA0B6]\n\t(No symbol) [0x00AA7E08]\n\t(No symbol) [0x00AA8F2D]\n\tGetHandleVerifier [0x00E48E3A+2540266]\n\tGetHandleVerifier [0x00E88959+2801161]\n\tGetHandleVerifier [0x00E8295C+2776588]\n\tGetHandleVerifier [0x00C72280+612144]\n\t(No symbol) [0x00B84F6C]\n\t(No symbol) [0x00B811D8]\n\t(No symbol) [0x00B812BB]\n\t(No symbol) [0x00B74857]\n\tBaseThreadInitThunk [0x75D16B89+25]\n\tRtlGetFullPathName_UEx [0x77968F9F+1215]\n\tRtlGetFullPathName_UEx [0x77968F6D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#click on international\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m international\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m international\u001b[38;5;241m.\u001b[39mclick\n\u001b[0;32m      4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: invalid locator\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00BE8893+48451]\n\t(No symbol) [0x00B7B8A1]\n\t(No symbol) [0x00A85058]\n\t(No symbol) [0x00AB0570]\n\t(No symbol) [0x00AB069B]\n\t(No symbol) [0x00ADDD92]\n\t(No symbol) [0x00ACA304]\n\t(No symbol) [0x00ADC482]\n\t(No symbol) [0x00ACA0B6]\n\t(No symbol) [0x00AA7E08]\n\t(No symbol) [0x00AA8F2D]\n\tGetHandleVerifier [0x00E48E3A+2540266]\n\tGetHandleVerifier [0x00E88959+2801161]\n\tGetHandleVerifier [0x00E8295C+2776588]\n\tGetHandleVerifier [0x00C72280+612144]\n\t(No symbol) [0x00B84F6C]\n\t(No symbol) [0x00B811D8]\n\t(No symbol) [0x00B812BB]\n\t(No symbol) [0x00B74857]\n\tBaseThreadInitThunk [0x75D16B89+25]\n\tRtlGetFullPathName_UEx [0x77968F9F+1215]\n\tRtlGetFullPathName_UEx [0x77968F6D+1165]\n"
     ]
    }
   ],
   "source": [
    "#click on international\n",
    "international=driver.find_element(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\")\n",
    "international.click\n",
    "time.sleep(3)\n",
    "\n",
    "# click on fixtures\n",
    "fixtures= driver.find_element(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "fixtures.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7545147d-175c-450c-a28b-fc42a07843ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match_title, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty list\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Scraping Match_title\n",
    "match_title= driver.find_elements(By.XPATH,\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in match_title:\n",
    "    Match_title.append(i.text)\n",
    "    \n",
    "#Scraping Series\n",
    "series= driver.find_elements(By.XPATH,\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "#Scraping Place\n",
    "place= driver.find_elements(By.XPATH,\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in place:\n",
    "    Place.append(i.text)   \n",
    "    \n",
    "#Scraping Date\n",
    "date= driver.find_elements(By.XPATH,\"//div[@class='fixture__full-date']\")\n",
    "for i in date:\n",
    "    Date.append(i.text)   \n",
    "    \n",
    "#Scraping Time\n",
    "time= driver.find_elements(By.XPATH,\"//span[@class='fixture__time']\")\n",
    "for i in time:\n",
    "    Time.append(i.text) \n",
    "\n",
    "Fixture=pd.DataFrame({})\n",
    "Fixture['Match_title']=Match_title\n",
    "Fixture['Series']=Series\n",
    "Fixture['Place']=Place\n",
    "Fixture['Date']=Date\n",
    "Fixture['Time']=Time\n",
    "Fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a76c2c8-9fd0-4b99-8960-c2a31769d691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scrape the details of State-wise GDP ofIndia fromstatisticstime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd40eb-76c4-4f74-9c73-4cf7e4f3196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c182d2c-aec4-4059-a606-26425aa776dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n",
    "import time\n",
    "time.sleep(4)\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bcf42a-ddd9-45e4-988e-a4f1d86171a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_at_current_price_19_20=[]\n",
    "GSDP_at_current_price_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "#Scraping Rank\n",
    "rank=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    if i.text is None:\n",
    "        Rank.append('--')\n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "        \n",
    "#Scraping State\n",
    "state=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "#Scraping GSDP_at_current_price_19_20\n",
    "gSDP_at_current_price_19_20=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "for i in gSDP_at_current_price_19_20:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_19_20.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_19_20.append(i.text)\n",
    "        \n",
    "#Scraping GSDP_at_current_price_18_19\n",
    "gSDP_at_current_price_18_19=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "for i in gSDP_at_current_price_18_19:\n",
    "    if i.text is None:\n",
    "        GSDP_at_current_price_18_19.append('--')\n",
    "    else:\n",
    "        GSDP_at_current_price_18_19.append(i.text)\n",
    "        \n",
    "#Scraping Share_18_19\n",
    "share_18_19=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "for i in share_18_19:\n",
    "    if i.text is None:\n",
    "        Share_18_19.append('--')\n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "        \n",
    "#Scraping GDP_billion\n",
    "gDP_billion=driver.find_elements(By.XPATH,\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "for i in gDP_billion:\n",
    "    if i.text is None:\n",
    "        GDP_billion.append('--')\n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating dataframe\n",
    "GDP_India=pd.DataFrame({})\n",
    "GDP_India['Rank']=Rank\n",
    "GDP_India['State']=State\n",
    "GDP_India['GSDP_at_current_price_19_20']=GSDP_at_current_price_19_20\n",
    "GDP_India['GSDP_at_current_price_18_19']=GSDP_at_current_price_18_19\n",
    "GDP_India['Share_18_19']=Share_18_19\n",
    "GDP_India['GDP_billion']=GDP_billion\n",
    "GDP_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e388b39-772f-431a-a484-4c704e3724ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f55ea8-4a10-4161-9d91-1b8cf10bb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b787ea-1252-45d9-ab96-029b583082db",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n",
    "import time\n",
    "time.sleep(4)\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8facf28-68d2-46d9-861b-d0eb14111756",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explore=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "Explore.click()\n",
    "\n",
    "Treading=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "Treading.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04565e74-30fc-44c2-8527-2d176752467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating emplty list \n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "#scraping Repository_title\n",
    "repository_title=driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']\")\n",
    "for i in repository_title:\n",
    "    if i.text is None:\n",
    "        Repository_title.append('--')\n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "        \n",
    "#scraping Repository_description\n",
    "repository_description=driver.find_elements(By.XPATH,\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "for i in repository_description:\n",
    "    if i.text is None:\n",
    "        Repository_description.append('--')\n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Contributors_count\n",
    "contributors_count=driver.find_elements(By.XPATH,\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "for i in contributors_count:\n",
    "    if i.text is None:\n",
    "        Contributors_count.append('--')\n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Language_used\n",
    "language_used=driver.find_elements(By.XPATH,\"//div[@class='f6 color-text-secondary mt-2']/span[1]\")\n",
    "for i in language_used:\n",
    "    if i.text is None:\n",
    "        Language_used.append('--')\n",
    "    else:\n",
    "        Language_used.append(i.text)   \n",
    "        \n",
    "Treding_rep=pd.DataFrame({})\n",
    "Treding_rep['Repository_title']= Repository_title\n",
    "Treding_rep['Repository_description']= Repository_description\n",
    "Treding_rep['Contributors_count']= Contributors_count\n",
    "Treding_rep['Language_used']= Language_used\n",
    "Treding_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef245f01-f7aa-4c16-98e2-100cf4b8cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of top 100 songs on billboard.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add15c87-a878-4637-b1a6-41818fad40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d342f-e2ec-4f4d-8f93-862a04baa3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1b178-cad8-48b6-87d9-e2f0b028f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Blank List\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "#Scraping Song_name\n",
    "song_name= driver.find_elements(By.XPATH,\"//span[@class='chart-element__information']/span[1]\")\n",
    "for i in song_name:\n",
    "    if i.text is None:\n",
    "        Song_name.append('--')\n",
    "    else:\n",
    "        Song_name.append(i.text)\n",
    "\n",
    "#Scraping Artist_name\n",
    "artist_name= driver.find_elements(By.XPATH,\"//span[@class='chart-element__information']/span[2]\")\n",
    "for i in artist_name:\n",
    "    if i.text is None:\n",
    "        Artist_name.append('--')\n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "        \n",
    "#Scraping Last_week_rank\n",
    "last_week_rank= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in last_week_rank:\n",
    "    if i.text is None:\n",
    "        Last_week_rank.append('--')\n",
    "    else:\n",
    "        Last_week_rank.append(i.text)\n",
    "        \n",
    "#Scraping Peak_rank\n",
    "peak_rank= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak_rank:\n",
    "    if i.text is None:\n",
    "        Peak_rank.append('--')\n",
    "    else:\n",
    "        Peak_rank.append(i.text)\n",
    "        \n",
    "#Scraping Weeks_on_board\n",
    "weeks_on_board= driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in weeks_on_board:\n",
    "    if i.text is None:\n",
    "        Weeks_on_board.append('--')\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "Hot_Songs=pd.DataFrame({})\n",
    "Hot_Songs['Song_name']=Song_name\n",
    "Hot_Songs['Artist_name']=Artist_name\n",
    "Hot_Songs['Last_week_rank']=Last_week_rank\n",
    "Hot_Songs['Peak_rank']=Peak_rank\n",
    "Hot_Songs['Weeks_on_board']=Weeks_on_board\n",
    "\n",
    "Hot_Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51431310-7fb7-4493-8cd3-f22bf81f6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of Data science recruiters from naukri.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897fdecf-458f-468f-adf5-dd86b45bd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/recruiters/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a61a8-1a7d-4bea-bb63-b98c5eb57f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search=driver.find_element(By.XPATH,\"//input[@class='sugInp']\")\n",
    "Search.send_keys(\"Data Science\")\n",
    "Search_btn=driver.find_element(By.XPATH,\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd90c6-f115-4c96-9d76-ce0933bbc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating emepty list\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire=[]\n",
    "Location=[]\n",
    "\n",
    "\n",
    "#Scraping Name \n",
    "name=driver.find_elements(By.XPATH,\"//span[@class='fl ellipsis']\")\n",
    "for i  in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Designation \n",
    "designation=driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\")\n",
    "for i  in designation:\n",
    "    Designation.append(i.text)    \n",
    "    \n",
    "#Scraping Company \n",
    "company=driver.find_elements(By.XPATH,\"//p[@class='highlightable']/a[2]\")\n",
    "for i  in company:\n",
    "    Company.append(i.text)   \n",
    "    \n",
    "    \n",
    "#Scraping Skills_they_hire \n",
    "skills_they_hire=driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")\n",
    "for i  in skills_they_hire:\n",
    "    Skills_they_hire.append(i.text)\n",
    "    \n",
    "\n",
    "    \n",
    "#Scraping Location \n",
    "location=driver.find_elements(By.XPATH,\"//p[@class='highlightable']/span[2]\")\n",
    "for i  in location:\n",
    "    if i.text is None:\n",
    "        \n",
    "        Location.append('--')\n",
    "    else:\n",
    "        Location.append(i.text)\n",
    "    \n",
    "Recruiters=pd.DataFrame({})\n",
    "Recruiters['Name']= Name[0:49]\n",
    "Recruiters['Designation']= Designation[0:49]\n",
    "Recruiters['Company']= Company[0:49]\n",
    "Recruiters['Skills_they_hire']= Skills_they_hire[0:49]\n",
    "Recruiters['Location']= Location[0:49]\n",
    "Recruiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82733550-8548-4f95-af2f-3dc1b4c76a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details of Highest sellingnovel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496cc47-d6a0-419a-90e7-632410ca0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\") \n",
    "time.sleep(4)\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5f15d-e824-46aa-a65d-4a4345a424c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df96c3-7cfd-4955-bdda-93079469175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scraping Book_name\n",
    "book_name=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in book_name:\n",
    "    if i.text is None:\n",
    "        Book_name.append('--')\n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "author_name=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in author_name:\n",
    "    if i.text is None:\n",
    "        Author_name.append('--')\n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "        \n",
    "# Scraping Volumes_sold\n",
    "volumes_sold=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in volumes_sold:\n",
    "    if i.text is None:\n",
    "        Volumes_sold.append('--')\n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "publisher=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    if i.text is None:\n",
    "        Publisher.append('--')\n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "        \n",
    "# Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    if i.text is None:\n",
    "        Genre.append('--')\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "\n",
    "Top_selling_book=pd.DataFrame({})\n",
    "Top_selling_book['Book_name']=Book_name\n",
    "Top_selling_book['Author_name']=Author_name\n",
    "Top_selling_book['Volumes_sold']=Volumes_sold\n",
    "Top_selling_book['Publisher']=Publisher\n",
    "Top_selling_book['Genre']=Genre\n",
    "Top_selling_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2237b-93f8-4280-8ed1-cd16a22e204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the details most watched tv series of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12688f5e-54a9-490a-a4f2-b97addf662d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\") \n",
    "url =\"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99e3e6-21a0-45e7-b9f1-4affab997161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Name=[]\n",
    "Year_Span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d13f6-b3e1-4569-8f6f-5b2774cd803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Name\n",
    "name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping Year_Span\n",
    "year_span=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in year_span:\n",
    "    Year_Span.append(i.text)\n",
    "\n",
    "    \n",
    "#Scraping Genre\n",
    "genre=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "#Scraping Run_time\n",
    "run_time=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in run_time:\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping Ratings\n",
    "ratings=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping Votes\n",
    "votes=driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small'][3]/span[2]\")\n",
    "for i in votes:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "Top_shows=pd.DataFrame({})\n",
    "Top_shows['Name']=Name\n",
    "Top_shows['Year_Span']=Year_Span\n",
    "Top_shows['Genre']=Genre\n",
    "Top_shows['Run_time']=Run_time\n",
    "Top_shows['Ratings']=Ratings\n",
    "Top_shows['Votes']=Votes\n",
    "Top_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d98a57-09c9-4886-ae59-55e016d927bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details of Datasetsfrom UCI machine learning repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b513d43-2dfd-4ab4-8a45-f1c61ba3faf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahee\\AppData\\Local\\Temp\\ipykernel_21876\\3124509337.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\sahee\\Downloads\\chromedriver_win32\") \n",
    "time.sleep(4)\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import click\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a18347a9-8d9d-4269-92d5-b6ac4218dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "view_dataset.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c32cae66-836e-45ba-9342-974903ac3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b96177-9c1b-48ed-bc2b-7d2f72cdcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Dataset name\n",
    "data_name= driver.find_elements(By.XPATH,\"//p[@class='normal']/b/a[1]\")\n",
    "for i in data_name:\n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#Scraping data Type\n",
    "data_type=driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[2]/p\")\n",
    "for i in data_type[1:]:\n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Task\n",
    "task= driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[3]/p\")\n",
    "for i in task[1:]:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "        \n",
    "time.sleep(4)\n",
    "#Scraping Attribute_type\n",
    "attribute_type= driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[4]/p\")\n",
    "for i in attribute_type[1:]:\n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "\n",
    "time.sleep(4)        \n",
    "#Scraping No_of_instances\n",
    "no_of_instances= driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[5]/p\")\n",
    "for i in no_of_instances[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "        \n",
    "time.sleep(4)   \n",
    "#Scraping No_of_attribute\n",
    "no_of_attribute= driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[6]/p\")\n",
    "for i in no_of_attribute[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "time.sleep(4)\n",
    "\n",
    "#Scraping Year\n",
    "year= driver.find_elements(By.XPATH,\"//table[@border='1']/tbody/tr/td[7]/p\")\n",
    "for i in year[1:]:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "        \n",
    "data_dataset=pd.DataFrame({})\n",
    "data_dataset['Dataset_name']= Dataset_name\n",
    "data_dataset['Data_type']= Data_type\n",
    "data_dataset['Task']=Task\n",
    "data_dataset['Attribute_type']= Attribute_type\n",
    "data_dataset['No_of_instances']= No_of_instances\n",
    "data_dataset['No_of_attribute']= No_of_attribute\n",
    "data_dataset['Year']=Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350678fc-41c5-4dbe-9c14-fc0934b4f22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a28e8-dfbc-4532-98fc-432eca8db5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e580aa-1848-4653-a7c2-3d51cb5dd83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
